{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1. Eigenvalues and Eigenvectors\n",
    "\n",
    "Include PageRank as a motivating example. But make sure to talk about linear transformations and the geometric view.\n",
    "\n",
    "Somewhere in here: case study of rotation matrices.\n",
    "\n",
    "\n",
    "<!-- Eigenvalues and eigenvectors, and how they relate to the geometry of linear transformations.\n",
    "\n",
    "Talk about the characteristic polynomial, and how it relates to the eigenvalues of a matrix.\n",
    "\n",
    "Talk about the geometric interpretation of eigenvalues and eigenvectors.\n",
    "\n",
    "Talk about the power method for finding eigenvalues and eigenvectors. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenvalues and Eigenvectors\n",
    "\n",
    "```{hint} Learning Objectives\n",
    "\n",
    "TODO\n",
    "```\n",
    "## Websites and Networks\n",
    "\n",
    "As we did at the start of the course, we'll start with an example that is rooted in application, and introduce the necessary mathematical machinery to study it. At the start of the course, we studied the ever-present problem of building models that make meaningful predictions about the future â€“ and rest assured, we will return to that problem shortly. For now, though, we'll start by studying the problem that led to the creation of Google, which you may have once heard of by the phrase \"the billion dollar eigenvalue.\"\n",
    "\n",
    "## The Punchline\n",
    "\n",
    "```{topic} Definition: Eigenvalues and Eigenvectors\n",
    "\n",
    "Suppose $A$ is an $n \\times n$ matrix. A **non-zero** vector $\\vec v \\in \\mathbb{R}^n$ is an **eigenvector** of $A$ if:\n",
    "\n",
    "$$A \\vec v = \\lambda \\vec v$$\n",
    "\n",
    "for some scalar $\\lambda \\in \\mathbb{R}$. The scalar $\\lambda$ is called the **eigenvalue** of $A$ corresponding to $\\vec v$.\n",
    "\n",
    "```\n",
    "\n",
    "On its own, this definition is a bit hard to parse. But, it really says something quite simple and profound:\n",
    "\n",
    "```{important}\n",
    "\n",
    "If $A$ is a matrix, and $\\vec v$ is an eigenvector of $A$, then $A \\vec v$ is a **vector that points in the same direction** as $\\vec v$!\n",
    "\n",
    "Let's put that another way. The function $f(\\vec v) = A \\vec v$ is a **linear transformation** that maps vectors in $\\mathbb{R}^n$ to vectors in $\\mathbb{R}^n$. Eigenvectors of $A$ are vectors whose directions are **unchanged** by the linear transformation $f$. The corresponding eigenvalues are the scalars by which the eigenvectors are scaled.\n",
    "\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
